# web??????
server.port=8080

# ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.api-key=${DEEP_SEEK_API_KEY}
langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5b

# ???????
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true

#DeepSeek
langchain4j.open-ai.chat-model.baseurl=https://api.deepseek.com
langchain4j.open-ai.chat-model.api-key=${DEEP_SEEK_API_KEY}
langchain4j.open-ai.chat-model.model-name=deepseek-chat

# ???????
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true
# ????debug??
logging.level.root=debug